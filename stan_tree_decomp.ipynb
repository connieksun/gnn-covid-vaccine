{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "#from owid_downloader import GenerateTrainingData\n",
    "#from utils import date_today, gravity_law_commute_dist\n",
    "\n",
    "os.environ['NUMEXPR_MAX_THREADS'] = '16'\n",
    "os.environ['NUMEXPR_NUM_THREADS'] = '8'\n",
    "\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import dgl\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from model import STAN\n",
    "\n",
    "import sklearn\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date = '2021-01-01'\n",
    "end_date = '2021-05-31'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data processing\n",
    "raw_data = pd.read_csv('https://raw.githubusercontent.com/owid/covid-19-data/master/public/data/owid-covid-data.csv', usecols=[\"location\", \"date\", \"total_cases\", \"new_cases_smoothed\", \"total_deaths\",\n",
    "                    \"new_deaths\", \"total_vaccinations\", \"people_fully_vaccinated\", \"new_vaccinations\", \"population\"])\n",
    "raw_data['date'] = pd.to_datetime(raw_data['date'])\n",
    "mask = (raw_data['date'] >= start_date) & (raw_data['date'] <= end_date) # & (raw_data['location'].isin(countries))\n",
    "raw_data = raw_data.loc[mask]\n",
    "#print(raw_data[raw_data['location'] == 'United States']['total_cases'].values[0])\n",
    "countries = []\n",
    "loc_list = list(raw_data['location'].unique())\n",
    "# only include countries that have more than 1000 total cases on start date and at least 1 death\n",
    "for loc in loc_list:\n",
    "    if raw_data[raw_data['location'] == loc][\"total_cases\"].values[0] > 1000 and \\\n",
    "        raw_data[raw_data['location'] == loc][\"total_deaths\"].values[0] > 0:\n",
    "        countries.append(loc)\n",
    "# hard-coded; these are problematic locations (non-countries) that need to be removed\n",
    "countries.remove(\"European Union\")\n",
    "countries.remove(\"Europe\")\n",
    "countries.remove(\"Africa\")\n",
    "countries.remove(\"Asia\")\n",
    "countries.remove(\"North America\")\n",
    "countries.remove(\"Oceania\")\n",
    "countries.remove(\"South America\")\n",
    "countries.remove(\"World\")\n",
    "countries.remove(\"Tajikistan\")\n",
    "mask = raw_data['location'].isin(countries)\n",
    "raw_data = raw_data.loc[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_loc = len(raw_data['location'].unique())\n",
    "print(n_loc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate Graph\n",
    "# add flight neighbors\n",
    "# for now, add a connection if there is any flight between the two countries between start and end date\n",
    "loc_list = list(raw_data['location'].unique())\n",
    "flight_counts = pd.read_csv('processed_flights/flight_counts_2021_all_to_05.csv')\n",
    "adj_map = {}\n",
    "for each_loc in loc_list:\n",
    "    df = flight_counts.loc[flight_counts[\"origin_country\"] == each_loc]\n",
    "    adj_map[each_loc] = set(df[\"destination_country\"].unique())\n",
    "flight_counts['day'] = pd.to_datetime(flight_counts['day'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add land neighbors\n",
    "import csv\n",
    "neighbor_reader = csv.reader(open('neighbors.csv', 'r'))\n",
    "neighbors = {}\n",
    "for row in neighbor_reader:\n",
    "   neighbors[row[0]] = row[1].split(',')\n",
    "for each_loc,connected in adj_map.items():\n",
    "    for neighbor in neighbors[each_loc]:\n",
    "        if neighbor in loc_list:\n",
    "            connected.add(neighbor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create graph\n",
    "rows = []\n",
    "cols = []\n",
    "for each_loc in adj_map:\n",
    "    for each_loc2 in adj_map[each_loc]:\n",
    "        if each_loc in loc_list and each_loc2 in loc_list:\n",
    "            rows.append(loc_list.index(each_loc))\n",
    "            cols.append(loc_list.index(each_loc2))\n",
    "#print(rows)\n",
    "#print(cols)\n",
    "g = dgl.graph((rows, cols))\n",
    "print(g.number_of_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(flight_counts.head())\n",
    "\n",
    "e_matrix = np.zeros((n_loc, n_loc)) # edge weight matrix for every time period \n",
    "df = flight_counts.groupby([\"origin_country\"])\n",
    "for loc in range(n_loc):\n",
    "    try:\n",
    "        src_df = df.get_group(loc_list[loc])\n",
    "        src_df = src_df.groupby([\"destination_country\"])\n",
    "        for loc2 in range(n_loc):\n",
    "            try:\n",
    "                dst_df = src_df.get_group(loc_list[loc2])\n",
    "                e_matrix[loc, loc2] = dst_df['flight_count'].sum()\n",
    "            except:\n",
    "                continue\n",
    "    except:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 50 # for now, include edges if there are >= 50 flights between the countries\n",
    "to_include = set()\n",
    "edge_list = []\n",
    "for orig,dest in zip(rows,cols):\n",
    "    if e_matrix[orig][dest] >= threshold:\n",
    "        edge_list.append([orig, dest])\n",
    "        to_include.add(orig)\n",
    "        to_include.add(dest)\n",
    "print(len(edge_list))\n",
    "print(len(to_include))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "\n",
    "G = nx.DiGraph()\n",
    "G.add_nodes_from(to_include)\n",
    "G.add_edges_from(edge_list)\n",
    "\n",
    "options = {\"with_labels\": True, \"node_color\": \"white\", \"edgecolors\": \"blue\"}\n",
    "\n",
    "fig = plt.figure(figsize=(6, 9))\n",
    "axgrid = fig.add_gridspec(3, 2)\n",
    "\n",
    "ax1 = fig.add_subplot(axgrid[0, 0])\n",
    "ax1.set_title(\"Bayesian Network\")\n",
    "pos = nx.nx_agraph.graphviz_layout(G, prog=\"neato\")\n",
    "nx.draw_networkx(G, pos=pos, **options)\n",
    "\n",
    "mg = nx.moral_graph(G)\n",
    "ax2 = fig.add_subplot(axgrid[0, 1], sharex=ax1, sharey=ax1)\n",
    "ax2.set_title(\"Moralized Graph\")\n",
    "nx.draw_networkx(mg, pos=pos, **options)\n",
    "\n",
    "jt = nx.junction_tree(G)\n",
    "ax3 = fig.add_subplot(axgrid[1:, :])\n",
    "ax3.set_title(\"Junction Tree\")\n",
    "ax3.margins(0.15, 0.25)\n",
    "nsize = [2000 * len(n) for n in list(jt.nodes())]\n",
    "pos = nx.nx_agraph.graphviz_layout(jt, prog=\"neato\")\n",
    "nx.draw_networkx(jt, pos=pos, node_size=nsize, **options)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "cdfa9ace6613655d28fa2370fe498fbea8375f41a5fc4e643d7f8a581612fdbd"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit ('tf-gpu': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
